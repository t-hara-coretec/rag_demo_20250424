{"content": "PydanticAI\nSkip to content\nIntroduction\nAgent Framework / shim to use Pydantic with LLMs\nPydanticAI is a Python agent framework designed to make it less painful to\nbuild production grade applications with Generative AI.\nFastAPI revolutionized web development by offering an innovative and ergonomic design, built on the foundation of\nPydantic\n.\nSimilarly, virtually every agent framework and LLM library in Python uses Pydantic, yet when we began to use LLMs in\nPydantic Logfire\n, we couldn't find anything that gave us the same feeling.\nWe built PydanticAI with one simple aim: to bring that FastAPI feeling to GenAI app development.\nWhy use PydanticAI\nBuilt by the Pydantic Team\n:\nBuilt by the team behind\nPydantic\n(the validation layer of the OpenAI SDK, the Anthropic SDK, LangChain, LlamaIndex, AutoGPT, Transformers, CrewAI, Instructor and many more).\nModel-agnostic\n:\nSupports OpenAI, Anthropic, Gemini, Deepseek, Ollama, Groq, Cohere, and Mistral, and there is a simple interface to implement support for\nother models\n.\nPydantic Logfire Integration\n:\nSeamlessly\nintegrates\nwith\nPydantic Logfire\nfor real-time debugging, performance monitoring, and behavior tracking of your LLM-powered applications.\nType-safe\n:\nDesigned to make\ntype checking\nas powerful and informative as possible for you.\nPython-centric Design\n:\nLeverages Python's familiar control flow and agent composition to build your AI-driven projects, making it easy to apply standard Python best practices you'd use in any other (non-AI) project.\nStructured Responses\n:\nHarnesses the power of\nPydantic\nto\nvalidate and structure\nmodel outputs, ensuring responses are consistent across runs.\nDependency Injection System\n:\nOffers an optional\ndependency injection\nsystem to provide data and services to your agent's\nsystem prompts\n,\ntools\nand\noutput validators\n.\nThis is useful for testing and eval-driven iterative development.\nStreamed Responses\n:\nProvides the ability to\nstream\nLLM responses continuously, with immediate validation, ensuring real time access to validated outputs.\nGraph Support\n:\nPydantic Graph\nprovides a powerful way to define graphs using typing hints, this is useful in complex applications where standard control flow can degrade to spaghetti code.\nHello World Example\nHere's a minimal example of PydanticAI:\nhello_world.py\nfrom\npydantic_ai\nimport\nAgent\nagent\n=\nAgent\n(\n# (1)!\n'google-gla:gemini-1.5-flash'\n,\nsystem_prompt\n=\n'Be concise, reply with one sentence.'\n,\n# (2)!\n)\nresult\n=\nagent\n.\nrun_sync\n(\n'Where does \"hello world\" come from?'\n)\n# (3)!\nprint\n(\nresult\n.\noutput\n)\n\"\"\"\nThe first known use of \"hello, world\" was in a 1974 textbook about the C programming language.\n\"\"\"\nWe configure the agent to use\nGemini 1.5's Flash\nmodel, but you can also set the model when running the agent.\nRegister a static\nsystem prompt\nusing a keyword argument to the agent.\nRun the agent\nsynchronously, conducting a conversation with the LLM.\n(This example is complete, it can be run \"as is\")\nThe exchange should be very short: PydanticAI will send the system prompt and the user query to the LLM, the model will return a text response.\nNot very interesting yet, but we can easily add \"tools\", dynamic system prompts, and structured responses to build more powerful agents.\nTools & Dependency Injection Example\nHere is a concise example using PydanticAI to build a support agent for a bank:\nbank_support.py\nfrom\ndataclasses\nimport\ndataclass\nfrom\npydantic\nimport\nBaseModel\n,\nField\nfrom\npydantic_ai\nimport\nAgent\n,\nRunContext\nfrom\nbank_database\nimport\nDatabaseConn\n@dataclass\nclass\nSupportDependencies\n:\n# (3)!\ncustomer_id\n:\nint\ndb\n:\nDatabaseConn\n# (12)!\nclass\nSupportOutput\n(\nBaseModel\n):\n# (13)!\nsupport_advice\n:\nstr\n=\nField\n(\ndescription\n=\n'Advice returned to the customer'\n)\nblock_card\n:\nbool\n=\nField\n(\ndescription\n=\n\"Whether to block the customer's card\"\n)\nrisk\n:\nint\n=\nField\n(\ndescription\n=\n'Risk level of query'\n,\nge\n=\n0\n,\nle\n=\n10\n)\nsupport_agent\n=\nAgent\n(\n# (1)!\n'openai:gpt-4o'\n,\n# (2)!\ndeps_type\n=\nSupportDependencies\n,\noutput_type\n=\nSupportOutput\n,\n# (9)!\nsystem_prompt\n=\n(\n# (4)!\n'You are a support agent in our bank, give the '\n'customer support and judge the risk level of their query.'\n),\n)\n@support_agent\n.\nsystem_prompt\n# (5)!\nasync\ndef\nadd_customer_name\n(\nctx\n:\nRunContext\n[\nSupportDependencies\n])\n->\nstr\n:\ncustomer_name\n=\nawait\nctx\n.\ndeps\n.\ndb\n.\ncustomer_name\n(\nid\n=\nctx\n.\ndeps\n.\ncustomer_id\n)\nreturn\nf\n\"The customer's name is\n{\ncustomer_name\n!r}\n\"\n@support_agent\n.\ntool\n# (6)!\nasync\ndef\ncustomer_balance\n(\nctx\n:\nRunContext\n[\nSupportDependencies\n],\ninclude_pending\n:\nbool\n)\n->\nfloat\n:\n\"\"\"Returns the customer's current account balance.\"\"\"\n# (7)!\nreturn\nawait\nctx\n.\ndeps\n.\ndb\n.\ncustomer_balance\n(\nid\n=\nctx\n.\ndeps\n.\ncustomer_id\n,\ninclude_pending\n=\ninclude_pending\n,\n)\n...\n# (11)!\nasync\ndef\nmain\n():\ndeps\n=\nSupportDependencies\n(\ncustomer_id\n=\n123\n,\ndb\n=\nDatabaseConn\n())\nresult\n=\nawait\nsupport_agent\n.\nrun\n(\n'What is my balance?'\n,\ndeps\n=\ndeps\n)\n# (8)!\nprint\n(\nresult\n.\noutput\n)\n# (10)!\n\"\"\"\nsupport_advice='Hello John, your current account balance, including pending transactions, is $123.45.' block_card=False risk=1\n\"\"\"\nresult\n=\nawait\nsupport_agent\n.\nrun\n(\n'I just lost my card!'\n,\ndeps\n=\ndeps\n)\nprint\n(\nresult\n.\noutput\n)\n\"\"\"\nsupport_advice=\"I'm sorry to hear that, John. We are temporarily blocking your card to prevent unauthorized transactions.\" block_card=True risk=8\n\"\"\"\nThis\nagent\nwill act as first-tier support in a bank. Agents are generic in the type of dependencies they accept and the type of output they return. In this case, the support agent has type\nAgent\n[\nSupportDependencies\n,\nSupportOutput\n]\n.\nHere we configure the agent to use\nOpenAI's GPT-4o model\n, you can also set the model when running the agent.\nThe\nSupportDependencies\ndataclass is used to pass data, connections, and logic into the model that will be needed when running\nsystem prompt\nand\ntool\nfunctions. PydanticAI's system of dependency injection provides a\ntype-safe\nway to customise the behavior of your agents, and can be especially useful when running\nunit tests\nand evals.\nStatic\nsystem prompts\ncan be registered with the\nsystem_prompt\nkeyword argument\nto the agent.\nDynamic\nsystem prompts\ncan be registered with the\n@agent.system_prompt\ndecorator, and can make use of dependency injection. Dependencies are carried via the\nRunContext\nargument, which is parameterized with the\ndeps_type\nfrom above. If the type annotation here is wrong, static type checkers will catch it.\ntool\nlet you register functions which the LLM may call while responding to a user. Again, dependencies are carried via\nRunContext\n, any other arguments become the tool schema passed to the LLM. Pydantic is used to validate these arguments, and errors are passed back to the LLM so it can retry.\nThe docstring of a tool is also passed to the LLM as the description of the tool. Parameter descriptions are\nextracted\nfrom the docstring and added to the parameter schema sent to the LLM.\nRun the agent\nasynchronously, conducting a conversation with the LLM until a final response is reached. Even in this fairly simple case, the agent will exchange multiple messages with the LLM as tools are called to retrieve an output.\nThe response from the agent will, be guaranteed to be a\nSupportOutput\n, if validation fails\nreflection\nwill mean the agent is prompted to try again.\nThe output will be validated with Pydantic to guarantee it is a\nSupportOutput\n, since the agent is generic, it'll also be typed as a\nSupportOutput\nto aid with static type checking.\nIn a real use case, you'd add more tools and a longer system prompt to the agent to extend the context it's equipped with and support it can provide.\nThis is a simple sketch of a database connection, used to keep the example short and readable. In reality, you'd be connecting to an external database (e.g. PostgreSQL) to get information about customers.\nThis\nPydantic\nmodel is used to constrain the structured data returned by the agent. From this simple definition, Pydantic builds the JSON Schema that tells the LLM how to return the data, and performs validation to guarantee the data is correct at the end of the run.\nComplete\nbank_support.py\nexample\nThe code included here is incomplete for the sake of brevity (the definition of\nDatabaseConn\nis missing); you can find the complete\nbank_support.py\nexample\nhere\n.\nInstrumentation with Pydantic Logfire\nTo understand the flow of the above runs, we can watch the agent in action using Pydantic Logfire.\nTo do this, we need to set up logfire, and add the following to our code:\nbank_support_with_logfire.py\n...\nfrom\npydantic_ai\nimport\nAgent\n,\nRunContext\nfrom\nbank_database\nimport\nDatabaseConn\nimport\nlogfire\nlogfire\n.\nconfigure\n()\n# (1)!\nlogfire\n.\ninstrument_asyncpg\n()\n# (2)!\n...\nsupport_agent\n=\nAgent\n(\n'openai:gpt-4o'\n,\ndeps_type\n=\nSupportDependencies\n,\noutput_type\n=\nSupportOutput\n,\nsystem_prompt\n=\n(\n'You are a support agent in our bank, give the '\n'customer support and judge the risk level of their query.'\n),\ninstrument\n=\nTrue\n,\n)\nConfigure logfire, this will fail if project is not set up.\nIn our demo,\nDatabaseConn\nuses\nasyncpg\nto connect to a PostgreSQL database, so\nlogfire.instrument_asyncpg()\nis used to log the database queries.\nThat's enough to get the following view of your agent in action:\nSee\nMonitoring and Performance\nto learn more.\nllms.txt\nThe PydanticAI documentation is available in the\nllms.txt\nformat.\nThis format is defined in Markdown and suited for large language models.\nTwo formats are available:\nllms.txt\n: a file containing a brief description\nof the project, along with links to the different sections of the documentation. The structure\nof this file is described in details\nhere\n.\nllms-full.txt\n: Similar to the\nllms.txt\nfile,\nbut every link content is included. Note that this file may be too large for some LLMs.\nAs of today, these files\ncannot\nbe natively leveraged by LLM frameworks or IDEs. Alternatively,\nan\nMCP server\ncan be implemented to properly parse the\nllms.txt\nfile.\nNext Steps\nTo try PydanticAI yourself, follow the instructions\nin the examples\n.\nRead the\ndocs\nto learn more about building applications with PydanticAI.\nRead the\nAPI Reference\nto understand PydanticAI's interface.", "metadata": {"source": "https://ai.pydantic.dev/#tools-dependency-injection-example", "title": "PydanticAI", "domain": "ai.pydantic.dev", "type": "web"}}